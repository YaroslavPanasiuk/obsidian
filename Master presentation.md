
1. тема магістерської роботи - СИСТЕМА ДЛЯ ВИРІШЕННЯ ЗАДАЧ DATA MINING НА ОСНОВІ ВЕЛИКИХ МОВНИХ МОДЕЛЕЙ

2. Отож, чому така тема? 
- Великі мовні моделі (я буду надалі називати LLM - це свіжа галузь для дослідження, яка розвивається шаленими темпами (можете бачити на слайді ріст кількості статей на теми, пов'язані з LLM - від 260 в 2021 році до 28000 в 2024 році))

- використання llm в data mining має наступні перспективи:
	- робота з неструктурованими наборами даних (текстом)
	- доступність у використанні (впровадження llm може спростити процес data minig)
	- автоматизація і масштабування складних завдань інтелектуального аналізу даних

3. Завданням роботи було Реалізувати систему вирішення задач data mining шляхом застосування LLM та порівняти результати з традиційними методами data mining через різні метрики

Для цього був розроблений веб застосунок у вигляді чат бота, який приймає запити природньої мови разом з вкладенням файлів досліджуваних даних і повертає відповідь на запит у форматі, таблиць та графіків, використовуючи велику мовну модель як бекенд

4. Для виконання поставленої задачі було реалізовано 5 наступних завдань data mining: підсумовування, класифікакія, кластеризація, регресійний аналіз та кореляційний аналіз і проведено порівняння ефективності виконання цих завдань із стандартними методами data mining. 

5. Було обрано мовну модель Mistral, бо її легко застосовувати через доступність документації та інтеграцію з іншими ресурсами, а також хорошу якість розуміння контексту та міркування (на слайді видно порівняння з іншими моделями)

Отож, як працює LLM
- Користувач задає запит у форматі природньої мови
- Текст розбивається на токени (слова, підслова або символи).
- Ці токени перетворюються на багатовимірні числові вектори.
- Трансформатори використовують механізми самоуваги, щоб визначити зв'язки між токенами, базуючись на відстані між векторами
- Модель передбачає наступний вектор у послідовності
- Ветор розкодовується у слово або частину слова

Проблема таких моделей полягає у Довжині контексту: вони не можуть працювати з дуже довгими контекстами (понад 4000 токенів), а це потрібно для завдань data mining для аналізу масивних файлів

6. для зчитування даних з масифних файлів застосовано векторні сховища даних і метод пошуку подібності FAISS (Facebook AI Similarity Search)

- Дані з файлу представлені у вигляді векторів високої розмірності. Вони зберігаються за межами LLM, у векторному сховищі. Коли LLM обробляє запит, запит так само перетворюється у набір векторів.
- Векторне сховище виконує пошук подібності, щоб знайти найбільш релевантні фрагменти даних, які відповідають запиту
- Знайдені фрагменти передаються до LLM як частина запиту. Відповідно кожен запит, який надсилається LLM, автоматичо доповнюється даними з імовірним джерелом відповіді на цей запит

Також нам потрібно візуального представити дані для аналізу. А LLM самі по собі не здатні це зробити, оскільки вони лиш генерують текст.

7. Тут у пригоді стають агенти. Вони виконують інструкції, написані LLM і повертають їм результат. Для візуалізації даних LLM генерує код для побудови графіків і агент запускає його на виконання. Потім отриманий графік представляється користувачеві.

8. Реалізація проєкту.
На слайді видно 2 сценарії використання реалізованого вебзастосунку
	- підсумовування youtube відео (зліва)
	Тут ми вставляємо посилання на відео в Youtube і задаємо запитаня про вміст відео. Отримаємо розгорнуту відповідь на основі вмісту відео
	- класифікація датасету за посиланням
	Тут ми вставили посилання на файл .csv з датасетом симптомів хвороб і отримали відображення класифікації цього датасету

9. Аналіз результатів
Тут наведено графіки з порівнянням ефективності виконання задач кластеризації та підсумовування на основі різних метрик. Подібні порівняння проведені для всіх досліджених завдань data mining. Найкраще вдаються задачі узагальнення (що не дивно, бо це робота з текстом, спеціалізація LLM), але і в інших завданнях LLM показує себе непогано (переважно не гірше за стандарнті методи). найгірше в порівнянні з класичними методами вдаються кластеризація та регресія

10. Висновки

LLM краще проявляють себе у завданнях, що вимагають контексту, семантики або складних взаємозв'язків, перевершуючи традиційні методи класифікації, узагальнення та регресії з неструктурованими даними. 

Однак стандартні методи ефективніші для простіших, добре структурованих завдань (кластеризації та регресії зі структурованими даними)

Отже, LLM на сьогодні можуть доповнити стандартні методи data mining, але не здатні замінити їх повноцінно



	- Виконаний програмний проект



	- Звіт досліджень



12. Висновки - 1 хв
	- ефективність та перспективи використання LLM в задачах іад





Робота присвячена актуальній темі застосування великих мовних моделей для вирішення задач інтелектуального аналізу даних (data mining). Серед позитивних рис – використання сучасних методів класифікації, кластеризації, регресії та кореляційного аналізу, а також інтеграція LLM для автоматизації складних завдань. 

До негативних сторін можна віднести ==недостатню грунтовність описів моделей==. Загалом, робота демонструє високий потенціал практичного застосування. (30 б.)




Позитивна сторона роботи: Чітка структурованість, реалізація сучасних методів data mining з використанням великих мовних моделей.
Зауваження: Необхідно було завершити ==доопрацювання діаграм==, підписів до зображень та форматування формул для завершення, форматування тексту роботи. Також, варто було ==більш ґрунтовно висвітлити таку тему, як великі мовні моделі.==



We introduce Mistral 7B, a 7–billion-parameter language model engineered for
superior performance and efficiency. Mistral 7B outperforms the best open 13B
model (Llama 2) across all evaluated benchmarks, and the best released 34B
model (Llama 1) in reasoning, mathematics, and code generation. Our model
leverages grouped-query attention (GQA) for faster inference, coupled with sliding
window attention (SWA) to effectively handle sequences of arbitrary length with a
reduced inference cost. We also provide a model fine-tuned to follow instructions,
Mistral 7B – Instruct, that surpasses Llama 2 13B – chat model both on human and
automated benchmarks. Our models are released under the Apache 2.0 license.



Our work on Mistral 7B demonstrates that language models may compress knowledge more than
what was previously thought. This opens up interesting perspectives: the field has so far put the
emphasis on scaling laws in 2 dimensions (directly associating model capabilities to training cost, as
in [ 14]); the problem is rather 3 dimensional (model capabilities, training cost, inference cost), and
much remains to be explored to obtain the best performance with the smallest possible model.



- It is **natively fluent in English, French, Spanish, German, and Italian,** with a nuanced understanding of grammar and cultural context.
    
- Its **32K tokens context window** allows precise information recall from large documents.
    
- Its **precise instruction-following** enables developers to design their **moderation policies** – we used it to set up the system-level moderation of le Chat.
    
- **It is natively capable of function calling.** This, along with constrained output mode, implemented on la Plateforme, enables application development and tech stack modernisation at scale.



1
Отож, тема магістерської роботи - СИСТЕМА ДЛЯ ВИРІШЕННЯ ЗАДАЧ DATA MINING НА ОСНОВІ ВЕЛИКИХ МОВНИХ МОДЕЛЕЙ

2
Отож, чому така тема? 
Не дуже досліджена галузь, наразі є не так багато статей на таке використання llm

водночас використання llm в data mining має наступні перспективи

Ці перспективи можете бачити на екрані, але на мій погляд головне те, що використання llm поєднує зрозумілість результатів з можливістю масштабувати досліджувані дані, а також простота користування


3
Тут видно формальні об'єкт дослідження, предмет і завдання, а я до цього додам, що маю на меті розробити веб застосунок у вигляді чат бота, який прийматиме запити природньої мови разом з вкладенням файлів досліджуваних даних і повертатиме відповідь на запит у форматі природньої мови, таблиць або графіків, використовуючи велику мовну модель як бекенд

Для виконання поставленої задачі було реалізовано 5 наступних завдань data mining: підсумовування, класифікакія, кластеризація, регресійний аналіз та кореляційний аналіз і проведено порівняння ефективності виконання цих завдань із стандартними методами data mining

4
Виклики:
- як вставити файли в якості контексту - LLM не здатні обробляти великі запити із масивними даними (зазвичай обмажуються декількома тисячами токенів). Тому потрібно якимось чином збільшити контекстне вікно
- як LLM загального пизначення зробити більш ефективною для вирішення специфічних завдань - LLM самі по собі не здатні ефективно виконувати завдання data mining, для цього їх потрібно донавчити або надати доступ до обширної бази знань.
- Як зробити візуалізацію даних - LLM не здатні виконувати жодних дій - вони лише генерують текст або зображення. Тому вони не здатні самостійно відображати інфографіку з аналізом даних 

5
Рішення викликів:
- для зчитування даних з масифних файлів застосовано векторні сховища даних і метод FAISS (Facebook AI Similarity Search)
Дані представлені у вигляді векторів високої розмірності, розбиті на фрагменти (наприклад, абзаци або речення). Вони зберігаються за межами LLM. Як LLM отримує доступ до цього сховища? - метод RAG. Він працює наступним чином:

- Для більш ефективного виконання задач Data mining застосовано метод RAG (генерація, доповнена ресурсами)

Коли LLM обробляє запит, запит вбудовується у вектор з даними з файлу.
Векторне сховище виконує пошук подібності, щоб знайти найбільш релевантні фрагменти даних.
Знайдені фрагменти передаються до LLM як частина запиту. Відповідно кожен запит, який надсилається LLM, автоматичо доповнюється даними з імовірним джерелом відповіді на цей запит

- Для візуалізації даних потрібно згенерувати код для побудови графіків і запустити його на виконання. Потім отримати побудований графік і представити його користувачеві. LLM може згенерувати код, але не може його виконати. Для цього використовуються агенти. Вони виконують інструкції, написані LLM і повертають їм результат

6
Робота програми
На слайді видно 2 сценарії 
- підсумовування youtube відео (зліва)
Тут ми вставляємо посилання на відео в Youtube і задаємо запитаня про вміст відео. Отримаємо розгорнуту відповідь на основі вмісту відео
- класифікація датасету за посиланням
Тут ми вставили посилання на файл .csv з датасетом симптомів хвороб і отримали відображення класифікації цього датасету

7
Аналіз результатів
Тут наведено графік з порівнянням ефективності виконання задачі класифікації методом лінійної регресії та з використанням LLM на основі різних метрик. Тут практично всюоди видно перевагу LLM у порівнянні зі стандартним методом: вища точність, нижча логарифмічна втрата, вищий рахунок F1, краща конкретність

Подібні порівняння проведені ще з 4-ма задачами data mining, і всюди LLM показує досить непогані результати. Найкраще вдаються задачі класифікації та узагальнення, найгірше - кластеризація та регресія
8
Висновки бачите на екрані. На цьому все.